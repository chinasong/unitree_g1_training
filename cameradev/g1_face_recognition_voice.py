import sys
import os
import time
import rospy
import cv2
import face_recognition
import numpy as np
from cv_bridge import CvBridge
from sensor_msgs.msg import Image

from unitree_sdk2py.core.channel import ChannelFactoryInitialize
from unitree_sdk2py.g1.audio.g1_audio_client import AudioClient

from unitree_sdk2py.g1.loco.g1_loco_client import LocoClient

bridge = CvBridge()
known_encodings = []
known_names = []
last_spoken = ""
last_spoken_time = time.time()

# åˆå§‹åŒ–æ‰‹åŠ¿çŠ¶æ€æ ‡è®°
hand_raised = False
last_detect_time = 0
owner_present = False

def init_audio_client(net_iface: str):
    # ChannelFactoryInitialize(0, net_iface)
    audio_client = AudioClient()
    audio_client.SetTimeout(10.0)
    audio_client.Init()
    audio_client.SetVolume(85)
    return audio_client

def speak(audio_client, text):
    print("ğŸ“¢", text)
    audio_client.TtsMaker(text, 0)

def load_known_faces(folder="faces"):
    for file in os.listdir(folder):
        path = os.path.join(folder, file)
        img = face_recognition.load_image_file(path)
        encodings = face_recognition.face_encodings(img)
        if encodings:
            for enc in encodings:
                known_encodings.append(enc)
                name = os.path.splitext(file)[0].split("_")[0]  # æˆªå–å‰ç¼€å
                known_names.append(name)
                print(f"âœ… å·²å­¦ä¹ ï¼š{name}")

# å…¨å±€çŠ¶æ€è®°å½•
name_last_time = {}
last_owner_seen_time = 0
REPEAT_DELAY = 6           # åŒä¸€ä¸ªäººè¯´è¯é—´éš”æ—¶é—´
OWNER_DISAPPEAR_DELAY = 5  # ä¸»äººç¦»å¼€å¤šä¹…åæ‰‹æ”¾ä¸‹

def image_callback(msg):
    global name_last_time, hand_raised, last_owner_seen_time

    frame = bridge.imgmsg_to_cv2(msg, "bgr8")
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_locations = face_recognition.face_locations(rgb_frame)
    encodings = face_recognition.face_encodings(rgb_frame, face_locations)

    current_time = time.time()
    recognized_names = []

    for encoding in encodings:
        matches = face_recognition.compare_faces(known_encodings, encoding)
        name = "é™Œç”Ÿäºº"
        if True in matches:
            index = matches.index(True)
            name = known_names[index]

        recognized_names.append(name)

        if name not in name_last_time or current_time - name_last_time[name] > REPEAT_DELAY:
            speak(audio_client, f"ä½ å¥½ï¼Œ{name}")
            name_last_time[name] = current_time

            if name == "ä¸»äºº" and not hand_raised:
                loco_client.ShakeHand()
                hand_raised = True

        if name == "ä¸»äºº":
            last_owner_seen_time = current_time

    # å¦‚æœæ¡æ‰‹çŠ¶æ€ä¸”ä¸»äººå·²ç¦»å¼€è¶…æ—¶
    if hand_raised and (current_time - last_owner_seen_time > OWNER_DISAPPEAR_DELAY):
        loco_client.HighStand()  # æˆ–è€…æ¢æˆå•ç‹¬â€œæ”¾æ‰‹â€çš„åŠ¨ä½œ
        hand_raised = False

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(f"Usage: python3 {sys.argv[0]} <networkInterface>")
        sys.exit(-1)

    net_iface = sys.argv[1]
    # åˆå§‹åŒ– DDS é€šé“ï¼ˆä¸€å®šè¦æ”¾åœ¨æœ€å‰ï¼‰
    ChannelFactoryInitialize(0, net_iface)

    audio_client = init_audio_client(net_iface)
    # åˆå§‹åŒ–åŠ¨ä½œå®¢æˆ·ç«¯
    loco_client = LocoClient()
    loco_client.SetTimeout(10.0)
    loco_client.Init()

    load_known_faces()
    rospy.init_node("g1_face_recognition_node")
    rospy.Subscriber("/camera/color/image_raw", Image, image_callback)
    print("ğŸ¥ G1 æ­£åœ¨è¿›è¡Œäººè„¸è¯†åˆ«ï¼ŒæŒ‰ Ctrl+C é€€å‡º")
    rospy.spin()